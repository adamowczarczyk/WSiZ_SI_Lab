{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Wczytaj przykładowy zbiór danych - dane dotyczące trzech gatunków Irysów\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Zobaczmy jakie dane mamy w zbiorze\n",
    "print('Elementy zbioru: ', list(iris.keys()))\n",
    "\n",
    "# Zobaczmy jak wyglądają elementy zbioru\n",
    "print('Typ pierwszego elementu z \\'data\\': ', type(iris['data'][0]))\n",
    "print('Kilka pierwszych elementów:')\n",
    "print(iris['data'][0:5])\n",
    "\n",
    "# Kwiaty mają swoje etykiety numeryczne...\n",
    "print('Pierwszy kwiat w zbiorze to: ', iris['target'][0])\n",
    "\n",
    "# ... a odpowiadające im nazwy są osobno\n",
    "print('Pierwszy kwiat w zbiorze (słownie) to: ', iris['target_names'][0])\n",
    "\n",
    "# Etykiety które występują\n",
    "print('Cechy irysów w zbiorze to: ', iris['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 1: sprawdź poniżej inne elementy wczytanego zbioru danych, w szczególności opis.\n",
    "# Opisz w max 3 zdaniach swoimi słowami co zawiera zbiór danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta sekcja jest tylko na potrzeby zobrazowania zbioru danych\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# wykresy będą tworzone przy pomocy pakietu seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# konwersja na obiekt pandas.DataFrame\n",
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# funkcja która nam zamieni wartości 0, 1, 2 na pełny opis tekstowy dla gatunku\n",
    "targets = map(lambda x: iris['target_names'][x], iris['target'] )\n",
    "\n",
    "# doklejenie informacji o gatunku do reszty dataframe\n",
    "iris_df['species'] = np.array(list(targets))\n",
    "\n",
    "# wykres\n",
    "sns.pairplot(iris_df, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zobaczmy jak naocznie wyglądają dane\n",
    "iris_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Podzielmy zbiór na cechy oraz etykiety\n",
    "# Konwencja, często spotykana w dokumentacji sklearn to X dla cech oraz y dla etykiet\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Używamy funkcji do podzielenia zbioru na zbiór uczący i zbiór testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Tworzymy klasyfikator k-NN używając parametru 5 sąsiadów\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Uczymy klasyfikator na zbiorze - zaskoczenie - uczącym\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Przewidujemy wartości dla zbioru testowego\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Sprawdzamy kilka pierwszych wartości przewidzianych\n",
    "print(y_pred[:5])\n",
    "\n",
    "# Sprawdzamy dokładność klasyfikatora\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na przykładzie dwóch cech sprawdźmy jakie są granice decyzyjne\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Tworzymy płaszczyznę wszystkich możliwych wartości dla cechy 0 oraz 2, z krokiem 0.1\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 2].min() - 1, X[:, 2].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# Uczymy klasyfikator na tylko dwóch wybranych cechach\n",
    "knn.fit(X_train[:, [0, 2]], y_train)\n",
    "\n",
    "# Przewidujemy każdy punkt na płaszczyźnie\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Tworzymy contourplot\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.bwr)\n",
    "plt.scatter(X[:, 0], X[:, 2], c=y, s=20, edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 2:\n",
    "# Stwórz listę kilku wybranych przez siebie wartości dla parametru n_neighbors\n",
    "# W pętli 'for' użyj kolejnych wartości parametru do stworzenia klasyfikatora\n",
    "# Następnie naucz go na danych uczących\n",
    "# Zapisz wynik scoringu na danych testowych do osobnej listy\n",
    "\n",
    "lista_n = []\n",
    "dokladnosci = []\n",
    "\n",
    "for n_neighb in lista_n:\n",
    "    \n",
    "    knn = ...\n",
    "    dokladnosc = knn.score(...)\n",
    "    dokladnosci.append(dokladnosc)\n",
    "\n",
    "# Wyświetl wykres zależności między liczbą sąsiadów a dokładnością.\n",
    "\n",
    "%matplotlib inline\n",
    "...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Wczytaj przykładowy zbiór danych - cyfry odręczne z MNIST\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Zobaczmy jakie dane mamy w zbiorze\n",
    "print('Elementy zbioru: ', list(digits.keys()))\n",
    "\n",
    "# Każda cyfra to po prostu macierz 8x8\n",
    "print('Typ pierwszego elementu z \\'images\\': ', type(digits['images'][0]))\n",
    "print(digits['images'][0])\n",
    "\n",
    "# Cyfry mają swoje etykiety\n",
    "print('Pierwsza cyfra w zbiorze to: ', digits['target'][0])\n",
    "\n",
    "# Możemy też wyświetlić dwuwymiarową macierz jako obrazek, za pomocą imshow\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Podzielmy zbiór na cechy oraz etykiety\n",
    "# Trzymamy się konwencji, X dla cech oraz y dla etykiet\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Używamy funkcji do podzielenia zbioru na zbiór uczący i zbiór testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Tworzymy klasyfikator k-NN używając parametru 5 sąsiadów\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Uczymy klasyfikator na zbiorze uczącym\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Sprawdzamy dokładność klasyfikatora\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdźmy coś więcej niż dokładność\n",
    "# na początek zapiszmy wyniki predykcji\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Sprawdźmy wyniki klasyfikacji\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Jak bardzo wyniki różnią się od prawdziwych wartości?\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opisy różnych metryk znajdziesz tutaj:\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "# Od biedy:\n",
    "# https://pl.wikipedia.org/wiki/Tablica_pomyłek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasyfikatory potrafią określać również prawdopodobieństwo przynależności do konkretnej klasy\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_test)\n",
    "\n",
    "# Sprawdźmy wyniki klasyfikacji dla kilku pierwszych wartości\n",
    "print(y_pred_proba[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Część 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 3:\n",
    "# wczytaj dane o winach za pomocą funkcji poniżej\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Zbadaj zbiór danych. Stwórz wykresy obrazujące ten zbiór danych.\n",
    "# Podziel zbiór danych na uczący i testowy.\n",
    "# Wytrenuj klasyfikator kNN\n",
    "# Dokonaj predykcji na zbiorze testowym\n",
    "# Wypisz raport z uczenia: confusion_matrix oraz classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie bonus:\n",
    "# Wczytaj dane za pomocą funkcji fetch_openml\n",
    "from sklearn.datasets import fetch_openml\n",
    "# Funkcja przyjmuje jako parametr nazwę zbioru danych z https://www.openml.org/search?type=data\n",
    "# Proponuję zbiór 'bank-marketing', ale możesz wybrać dowolny inny z kategorii \"klasyfikacja\"\n",
    "# Reszta: jak w zadaniu 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
